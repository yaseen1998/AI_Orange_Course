{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend import preprocessing\n",
    "from sklearn.preprocessing import RobustScaler,MinMaxScaler,StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv/assigment/credit_score_clean_extraction.csv')\n",
    "x = df.drop(\"Credit_Score\", axis=1)\n",
    "y = df[\"Credit_Score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_min_max = preprocessing.minmax_scaling(df, columns=x.columns)\n",
    "new_df = pd.concat([scaler_min_max,y],axis=1)\n",
    "new_df.to_csv('../csv/assigment/scale_min_max.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_ru = RobustScaler()\n",
    "\n",
    "# Fit the scaler to the data\n",
    "scaler_ru.fit(x)\n",
    "\n",
    "# Transform the data using the scaler\n",
    "scaled_data = scaler_ru.transform(x)\n",
    "scale_Robust= pd.DataFrame(scaled_data, columns=x.columns)\n",
    "new_df = pd.concat([scale_Robust,y],axis=1)\n",
    "new_df.to_csv('../csv/assigment/scale_Robust.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Loan\n",
      "Not Specified\n",
      "Auto Loan\n",
      "Mortgage Loan\n",
      "Debt Consolidation Loan\n",
      "No Data\n",
      "Credit-Builder Loan\n",
      "Payday Loan\n",
      "Personal Loan\n",
      "Home Equity Loan\n",
      "Payment_Behaviour_High_spent_Large_value_payments\n",
      "Payment_Behaviour_High_spent_Medium_value_payments\n",
      "Payment_Behaviour_High_spent_Small_value_payments\n",
      "Payment_Behaviour_Low_spent_Large_value_payments\n",
      "Payment_Behaviour_Low_spent_Medium_value_payments\n",
      "Payment_Behaviour_Low_spent_Small_value_payments\n",
      "Occupation_Accountant\n",
      "Occupation_Architect\n",
      "Occupation_Developer\n",
      "Occupation_Doctor\n",
      "Occupation_Engineer\n",
      "Occupation_Entrepreneur\n",
      "Occupation_Journalist\n",
      "Occupation_Lawyer\n",
      "Occupation_Manager\n",
      "Occupation_Mechanic\n",
      "Occupation_Media_Manager\n",
      "Occupation_Musician\n",
      "Occupation_Scientist\n",
      "Occupation_Teacher\n",
      "Occupation_Writer\n"
     ]
    }
   ],
   "source": [
    "scaled_min = x.copy()\n",
    "for column in scaled_min.columns:\n",
    "    try:\n",
    "        data = scaled_min[column]\n",
    "        Q1 = data.quantile(0.25)\n",
    "        Q3 = data.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        clipped_data = np.clip(data, lower_bound, upper_bound)  # Define appropriate bounds\n",
    "        reshaped = clipped_data.values.reshape(-1, 1)  # Reshape your data\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(reshaped)\n",
    "        scaled_min[column] = scaled_data\n",
    "    except Exception as e:\n",
    "        print(column)\n",
    "        continue\n",
    "new_df = pd.concat([scaled_min,y],axis=1)\n",
    "new_df.to_csv('../csv/assigment/scale_min_sklearn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(x)\n",
    "scaled_st = pd.DataFrame(scaled_data, columns=x.columns)    \n",
    "new_df = pd.concat([scaled_st,y],axis=1)\n",
    "new_df.to_csv('../csv/assigment/scale_standard.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaseen/developer/AI/AI_Orange_Course/.venv/lib/python3.10/site-packages/pandas/core/internals/blocks.py:329: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = func(self.values, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "log_transformed_data = np.log1p(x)  # Applying log transformation\n",
    "scaler_min_2 = MinMaxScaler()  # You can also use RobustScaler here\n",
    "scaled_data = scaler_min_2.fit_transform(log_transformed_data)\n",
    "scaled_log = pd.DataFrame(scaled_data, columns=x.columns)   \n",
    "new_df = pd.concat([scaled_log,y],axis=1)\n",
    "new_df.to_csv('../csv/assigment/scale_log.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 60)\n",
      "(100000, 60)\n"
     ]
    }
   ],
   "source": [
    "scaled_min_max = pd.read_csv('../csv/assigment/scale_min_max.csv')\n",
    "scaled_min_sklearn= pd.read_csv('../csv/assigment/scale_min_sklearn.csv')\n",
    "scaled_log= pd.read_csv('../csv/assigment/scale_log.csv')\n",
    "print(scaled_log.shape)\n",
    "print(scaled_min_max.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
